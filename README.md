# FastAPI LLM Benchmark Application

## Описание проекта

Проект представляет собой FastAPI-сервер для взаимодействия с языковыми моделями через OpenRouter API. Сервер предоставляет endpoints для получения списка доступных моделей, генерации текста и проведения benchmark-тестирования производительности моделей.

## Функциональность

### Реализованные возможности

**Уровень 1:**
- GET `/models` - получение списка бесплатных текстовых моделей с OpenRouter
- POST `/generate` - генерация текста с помощью выбранной модели
- Логирование ошибок в файл `server_logs.txt`
- Конфигурация через `.env` файл

**Уровень 2:**
- Поддержка параметра `max_tokens` в генерации
- Возврат метрик: `response`, `tokens_used`, `latency_seconds`
- POST `/benchmark` - проведение тестирования на данных из файла с промптами
- Сохранение результатов benchmark в CSV формате и возврат JSON
- Статистика latency: среднее, минимум, максимум, стандартное отклонение

**Уровень 3:**
- Поддержка stream-режима через SSE (`?stream=true`)
- Параллельное выполнение benchmark-тестов для увеличения производительности
- Результаты тестов и примеры ответов лежат в папке results в корневой директории

## Структура проекта

```
llm-test-task/
├── core/
│   ├── config.py          # Конфигурация приложения
│   └── logging.py         # Настройка логирования
├── routers/
│   ├── models.py          # endpoints для работы с моделями
│   ├── completion.py      # endpoints генерации текста
│   ├── health.py          # healthcheck
│   └── benchmark.py       # endpoints benchmark-тестирования
├── schemas/
│   ├── benchmark.py       # Pydantic схемы запросов/ответов
│   └── completion.py      
├── services/
│   ├── benchmark.py       # Сервис для бенчмарка (вынесен чтобы не выполнять много в слое апи)
│   └── openrouter.py      # Сервис для работы с OpenRouter API
└── main.py               # Основное приложение
```

## Установка и запуск

### Требования
- Python 3.10+
- FastAPI
- Uvicorn
- OpenRouter API ключ

### Установка зависимостей
```bash
pip install -r requirements.txt
```

### Настройка окружения
Создайте файл `.env` в llm-test-task:
```env
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

### Запуск сервера
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## API Endpoints

### GET /models
Возвращает список доступных бесплатных моделей.

**Пример ответа:**
```json
{
  "models": [
    "deepseek/deepseek-chat-v3.1:free",
    "z-ai/glm-4.5-air:free", 
    "moonshotai/kimi-k2:free"
  ]
}
```

### POST /generate
Генерирует текст с помощью указанной модели.

**Параметры:**
- `prompt`: текст запроса (обязательный)
- `model`: идентификатор модели (обязательный)
- `max_tokens`: максимальное количество токенов (по умолчанию: 512)
- `stream`: включить stream-режим (по умолчанию: false)

**Пример запроса:**
```json
{
  "prompt": "Напиши стихотворение про Python",
  "model": "moonshotai/kimi-k2:free",
  "max_tokens": 200
}
```

**Пример ответа:**
```json
{
  "response": "Текст сгенерированный моделью...",
  "tokens_used": 150,
  "latency_seconds": 2.45
}
```

### POST /benchmark
Проводит benchmark-тестирование модели.

**Параметры:**
- `prompt_file`: текстовый файл с промптами (каждая строка - отдельный промпт)
- `model`: идентификатор модели для тестирования
- `runs`: количество запусков для каждого промпта (по умолчанию: 5)

**Пример ответа:**
```json
{
  "avg": 1.89,
  "min": 1.15,
  "max": 3.21,
  "std_dev": 0.87,
  "total_runs": 15,
  "successful_runs": 14,
  "total_tokens": 1250
}
```

## Особенности реализации

### Менеджер моделей
- Автоматическая загрузка моделей при старте приложения
- Фильтрация только бесплатных текстовых моделей (конфигурируемо)

### Логирование
- Запись ошибок в файл `server_logs.txt`
- Единый формат логов: `timestamp - logger_name - level - message`
- Дублирование логов в консоль для разработки

### Benchmark система
- Параллельное выполнение запросов для увеличения производительности (asyncio.gather)
- Ограничение количества одновременных соединений
- Детальная статистика в JSON ответе
- Автоматическое сохранение результатов в CSV формате
- Добавлены результаты замеров бенчмарков на разных моделях

### Обработка ошибок
- Централизованная обработка исключений
- Валидация входных параметров через pydantic

## Качество кода

- Типизация с помощью Pydantic
- Форматирование кода с помощью Black
- Сортировка импортов с isort
- Разделение ответственности между модулями
- Асинхронная обработка запросов

## Резюме

Проект демонстрирует лучшие практики разработки на FastAPI, включая структурирование проекта, обработку ошибок, логирование и работу с внешними API. 
Код готов к использованию в production-среде и может быть легко расширен дополнительной функциональностью.

Прошу прислать обратную связь (какой бы она ни была) любым удобным способом - хоть тут на гите.

## Контакты

Telegram: @Aaaarbis
E-mail: djmail20051@gmail.com
